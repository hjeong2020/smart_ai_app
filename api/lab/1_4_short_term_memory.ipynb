{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-14T21:57:23.838740Z",
     "start_time": "2025-10-14T21:57:23.401765Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"http://localhost:12434/engines/v1\",\n",
    "    api_key=\"docker\",\n",
    "    temperature=0,\n",
    "    model=\"ai/gemma3\"\n",
    ")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"ai/phi4\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url=\"http://localhost:12434/engines/v1\",\n",
    "    api_key=\"docker\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T21:57:36.707787Z",
     "start_time": "2025-10-14T21:57:25.529963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=llm,\n",
    "            max_tokens_before_summary=4000,  # Trigger summarization at 4000 tokens\n",
    "            messages_to_keep=20,  # Keep last 20 messages after summary\n",
    "        )\n",
    "    ],\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\"\"\"\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Your name is Bob!\n",
    "\"\"\""
   ],
   "id": "3c58369c4e0b9cf4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Your name is Bob! ðŸ˜Š You told me that at the beginning. \n",
      "\n",
      "Is there anything else youâ€™d like to talk about?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n================================== Ai Message ==================================\\n\\nYour name is Bob!\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T22:00:57.563431Z",
     "start_time": "2025-10-14T22:00:57.526771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Access memory\n",
    "from typing import Annotated\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.tools import InjectedState\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    user_id: str\n",
    "\n",
    "def get_user_info(\n",
    "    state: Annotated[CustomState, InjectedState]\n",
    ") -> str:\n",
    "    \"\"\"Look up user info.\"\"\"\n",
    "    user_id = state[\"user_id\"]\n",
    "    return \"User is John Smith\" if user_id == \"user_123\" else \"Unknown user\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_user_info],\n",
    "    state_schema=CustomState,\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": \"look up user information\",\n",
    "    \"user_id\": \"user_123\"\n",
    "})\n",
    "print(result[\"messages\"][-1].content)\n",
    "# > User is John Smith."
   ],
   "id": "15a4b9ad3fc3678",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_agent() got an unexpected keyword argument 'state_schema'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 16\u001B[39m\n\u001B[32m     13\u001B[39m     user_id = state[\u001B[33m\"\u001B[39m\u001B[33muser_id\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     14\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mUser is John Smith\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m user_id == \u001B[33m\"\u001B[39m\u001B[33muser_123\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mUnknown user\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m agent = \u001B[43mcreate_agent\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mget_user_info\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     19\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstate_schema\u001B[49m\u001B[43m=\u001B[49m\u001B[43mCustomState\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     22\u001B[39m result = agent.invoke({\n\u001B[32m     23\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mlook up user information\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     24\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33muser_id\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33muser_123\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     25\u001B[39m })\n\u001B[32m     26\u001B[39m \u001B[38;5;28mprint\u001B[39m(result[\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m][-\u001B[32m1\u001B[39m].content)\n",
      "\u001B[31mTypeError\u001B[39m: create_agent() got an unexpected keyword argument 'state_schema'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T22:02:22.983137Z",
     "start_time": "2025-10-14T22:02:18.646649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prompt\n",
    "\n",
    "from langchain.messages import AnyMessage\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langgraph.runtime import get_runtime\n",
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "class CustomContext(TypedDict):\n",
    "    user_name: str\n",
    "\n",
    "\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather in a city.\"\"\"\n",
    "    return f\"The weather in {city} is always sunny!\"\n",
    "\n",
    "\n",
    "@dynamic_prompt\n",
    "def dynamic_system_prompt(request: ModelRequest) -> str:\n",
    "    user_name = request.runtime.context[\"user_name\"]\n",
    "    system_prompt = f\"You are a helpful assistant. Address the user as {user_name}.\"\n",
    "    return system_prompt\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[dynamic_system_prompt],\n",
    "    context_schema=CustomContext,\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    context=CustomContext(user_name=\"John Smith\"),\n",
    ")\n",
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ],
   "id": "c0272b254c2cb3f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is the weather in SF?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (YX0XfYILrouwVxPKk2lYXZMXY1U7UR1x)\n",
      " Call ID: YX0XfYILrouwVxPKk2lYXZMXY1U7UR1x\n",
      "  Args:\n",
      "    city: SF\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "The weather in SF is always sunny!\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "The weather in SF is always sunny!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T22:04:09.939172Z",
     "start_time": "2025-10-14T22:03:33.589407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Before model\n",
    "\n",
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[],\n",
    "    middleware=[trim_messages]\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\"\"\"\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Your name is Bob. You told me that earlier.\n",
    "If you'd like me to call you a nickname or use a different name, just say the word.\n",
    "\"\"\""
   ],
   "id": "e381e650b90ba58b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "As an AI, I have no way of knowing your name! You haven't told me. ðŸ˜Š \n",
      "\n",
      "You can tell me if you'd like!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n================================== Ai Message ==================================\\n\\nYour name is Bob. You told me that earlier.\\nIf you'd like me to call you a nickname or use a different name, just say the word.\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# After model\n",
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import after_model\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "@after_model\n",
    "def validate_response(state: AgentState, runtime: Runtime) -> dict | None:\n",
    "    \"\"\"Remove messages containing sensitive words.\"\"\"\n",
    "    STOP_WORDS = [\"password\", \"secret\"]\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if any(word in last_message.content for word in STOP_WORDS):\n",
    "        return {\"messages\": [RemoveMessage(id=last_message.id)]}\n",
    "    return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[validate_response],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")"
   ],
   "id": "486115a72a89d46c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
