services:
  llm:
    provider:
      type: model
      options:
        model: ai/gemma3

  api:
    build:
      context: ./api
    ports:
      - "8000:8000"
    depends_on:
      - llm

  ui:
    build:
      context: ./ui
    ports:
      - "3000:5173" #localhost:3000
    depends_on:
      - api
